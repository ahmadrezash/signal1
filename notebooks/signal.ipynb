{
 "nbformat": 4,
 "nbformat_minor": 0,
 "metadata": {
  "kernelspec": {
   "name": "python3",
   "language": "python",
   "display_name": "Python 3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  },
  "colab": {
   "name": "Copy of signal.ipynb",
   "version": "0.3.2",
   "provenance": [],
   "collapsed_sections": []
  },
  "accelerator": "GPU",
  "pycharm": {
   "stem_cell": {
    "cell_type": "raw",
    "source": [],
    "metadata": {
     "collapsed": false
    }
   }
  }
 },
 "cells": [
  {
   "cell_type": "code",
   "metadata": {
    "id": "1OCCVamxDXzL",
    "colab_type": "code",
    "colab": {},
    "pycharm": {
     "is_executing": false
    }
   },
   "source": [
    "import seaborn as sn\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from pathlib import Path\n",
    "import os\n",
    "from scipy.io import loadmat\n"
   ],
   "execution_count": 40,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "TwXyEf0oPB4J",
    "colab_type": "code",
    "outputId": "cedcae12-f947-42ed-dc5a-01d909f7914f",
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 122
    },
    "pycharm": {
     "is_executing": false
    }
   },
   "source": [
    "mats = []\n",
    "\n",
    "disorder =  Path('./').absolute().parent.joinpath('data','New_Shuffled_Train(disorder)')\n",
    "normal = Path('./').absolute().parent.joinpath('data','New_Shuffled_Train_normal')\n"
   ],
   "execution_count": 41,
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "outputs": [],
   "source": [
    "x = []\n",
    "y = []\n",
    "for file in os.listdir( normal ) :\n",
    "    x.append( loadmat( str(normal)+'/'+file )[file[:-4]].T )\n",
    "    y.append(np.ones((295,19,2)))\n",
    "\n",
    "for file in os.listdir( disorder ) :\n",
    "    x.append( loadmat( str(disorder)+'/'+file )[file[:-4]].T )\n",
    "    y.append(np.zeros((295,19,2)))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": false
    }
   }
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "-tVC2T7nDXzZ",
    "colab_type": "code",
    "outputId": "3c0b3c1d-9b18-4d8f-90db-7cbaad30e0a3",
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "pycharm": {
     "is_executing": false
    }
   },
   "source": [
    "len(x)\n",
    "type"
   ],
   "execution_count": 39,
   "outputs": [
    {
     "data": {
      "text/plain": "328"
     },
     "metadata": {},
     "output_type": "execute_result",
     "execution_count": 39
    }
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "nPTGmTlWDXzb",
    "colab_type": "code",
    "colab": {}
   },
   "source": [
    "# import regx\n",
    "# np.fromregex\n",
    "len(mats)\n",
    "\n",
    "a = np.random.randint(len(mats),size=16)\n",
    "subset = [mats[i] for i in a]"
   ],
   "execution_count": 0,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "_gU2qRbCkdZb",
    "colab_type": "code",
    "colab": {}
   },
   "source": [
    "mats[0].shape\n",
    "np.ones((295,19,2))"
   ],
   "execution_count": 0,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "iJjsAU-1lte3",
    "colab_type": "code",
    "colab": {}
   },
   "source": [
    "fig = plt.figure(figsize=(20,12))\n",
    "# plt.figure(figsize=(20,8))\n",
    "for i in range(len(subset)):\n",
    "  for j in range(18):\n",
    "#   print(i)\n",
    "    plt.subplot(18, 1, i+1)\n",
    "    plt.plot(subset[i][j])\n",
    "\n"
   ],
   "execution_count": 0,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "JTu2kTlO4diu",
    "colab_type": "code",
    "colab": {}
   },
   "source": [
    "x = (np.array(x))\n",
    "y = (np.array(y))\n",
    "import sklearn.model_selection as a\n",
    "x_train, x_test, y_train, y_test = a.train_test_split(x, y, test_size=0.1)\n",
    "\n"
   ],
   "execution_count": 0,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "KwuuZLfq83vQ",
    "colab_type": "code",
    "outputId": "e04ca19d-7dee-4762-de3f-052c7a9b3b4f",
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    }
   },
   "source": [
    "x_train.shape\n",
    "x_train.shape[1:]\n",
    "x_train.shape\n",
    "# y_train = y_train.reshape(295,19,2)\n",
    "\n"
   ],
   "execution_count": 0,
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "(295, 19, 15360)"
      ]
     },
     "metadata": {
      "tags": []
     },
     "execution_count": 96
    }
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "cu-o_Z8Kqj95",
    "colab_type": "code",
    "outputId": "91836902-9f3c-4246-b6fe-5cef919dba9a",
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 374
    }
   },
   "source": [
    "from keras.models import Sequential\n",
    "import keras\n",
    "from keras.layers import Dense\n",
    "from keras.utils import to_categorical\n",
    "import random\n",
    "from keras.utils import plot_model\n",
    "import pydot\n",
    "import matplotlib.pyplot as plt\n",
    "# Sequential is a fully connected network\n",
    "model = Sequential()\n",
    "\n",
    "# 32 inputs and 1 neuron in the first layer (hidden layer)\n",
    "model.add(Dense(units=128*4, activation='relu' ))\n",
    "\n",
    "# 2 output layer \n",
    "model.add(Dense(128*4, activation='relu'))\n",
    "\n",
    "model.add(Dense(2, activation='sigmoid'))\n",
    "\n",
    "model.compile(loss='binary_crossentropy', \n",
    "              optimizer='rmsprop', \n",
    "              metrics=['accuracy'])\n",
    "\n",
    "# epochs is the number of times to retrain over the same data set\n",
    "# batch_size is how may elements to process in parallel at one go\n",
    "history = model.fit((x_train), (y_train), epochs=25, batch_size=1000, verbose=1, validation_split=0.1)\n",
    "\n",
    "model.summary()\n",
    "# weights, biases = model.layers[0].get_weights()\n",
    "# print(\"weights\",weights.size, weights, \"biases\", biases)\n"
   ],
   "execution_count": 0,
   "outputs": [
    {
     "output_type": "error",
     "ename": "ValueError",
     "evalue": "ignored",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-97-844858524fc3>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     24\u001b[0m \u001b[0;31m# epochs is the number of times to retrain over the same data set\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     25\u001b[0m \u001b[0;31m# batch_size is how may elements to process in parallel at one go\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 26\u001b[0;31m \u001b[0mhistory\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0my_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m25\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1000\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalidation_split\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     27\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     28\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msummary\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, **kwargs)\u001b[0m\n\u001b[1;32m    950\u001b[0m             \u001b[0msample_weight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msample_weight\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    951\u001b[0m             \u001b[0mclass_weight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mclass_weight\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 952\u001b[0;31m             batch_size=batch_size)\n\u001b[0m\u001b[1;32m    953\u001b[0m         \u001b[0;31m# Prepare validation data.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    954\u001b[0m         \u001b[0mdo_validation\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/keras/engine/training.py\u001b[0m in \u001b[0;36m_standardize_user_data\u001b[0;34m(self, x, y, sample_weight, class_weight, check_array_lengths, batch_size)\u001b[0m\n\u001b[1;32m    787\u001b[0m                 \u001b[0mfeed_output_shapes\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    788\u001b[0m                 \u001b[0mcheck_batch_axis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m  \u001b[0;31m# Don't enforce the batch size.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 789\u001b[0;31m                 exception_prefix='target')\n\u001b[0m\u001b[1;32m    790\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    791\u001b[0m             \u001b[0;31m# Generate sample-wise weight values given the `sample_weight` and\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/keras/engine/training_utils.py\u001b[0m in \u001b[0;36mstandardize_input_data\u001b[0;34m(data, names, shapes, check_batch_axis, exception_prefix)\u001b[0m\n\u001b[1;32m    126\u001b[0m                         \u001b[0;34m': expected '\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mnames\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m' to have '\u001b[0m \u001b[0;34m+\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    127\u001b[0m                         \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m' dimensions, but got array '\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 128\u001b[0;31m                         'with shape ' + str(data_shape))\n\u001b[0m\u001b[1;32m    129\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mcheck_batch_axis\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    130\u001b[0m                     \u001b[0mdata_shape\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdata_shape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: Error when checking target: expected dense_100 to have 3 dimensions, but got array with shape (295, 295, 19, 2)"
     ]
    }
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "JmETr0usFYEK",
    "colab_type": "code",
    "colab": {}
   },
   "source": [
    ""
   ],
   "execution_count": 0,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "cjAIn0--3_4E",
    "colab_type": "code",
    "colab": {}
   },
   "source": [
    "# Plot training & validation accuracy values\n",
    "plt.plot(history.history['acc'])\n",
    "plt.plot(history.history['val_acc'])\n",
    "plt.title('Model accuracy')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.xlabel('Epoch')\n",
    "plt.legend(['Train', 'Validate'], loc='upper left')\n",
    "plt.show()\n",
    "\n",
    "# Plot training & validation loss values\n",
    "plt.plot(history.history['loss'])\n",
    "plt.plot(history.history['val_loss'])\n",
    "plt.title('Model loss')\n",
    "plt.ylabel('Loss')\n",
    "plt.xlabel('Epoch')\n",
    "plt.legend(['Train', 'Validate'], loc='upper left')\n",
    "plt.show()"
   ],
   "execution_count": 0,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "x-o-gpN059n5",
    "colab_type": "code",
    "colab": {}
   },
   "source": [
    "model.evaluate(x = x_test,y=y_test)"
   ],
   "execution_count": 0,
   "outputs": []
  }
 ]
}